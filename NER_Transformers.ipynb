{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPnLkUPnUkIrS/bLqu18Ch6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eddy-Emmanuel/NER-Transformer/blob/main/NER_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aDyn_1WhnxRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de9ed3f2-6d47-45d6-87ee-93877d8e1278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/183.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer"
      ],
      "metadata": {
        "id": "qC5APWv_sld2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conllpp = load_dataset(\"ZihanWangKi/conllpp\")"
      ],
      "metadata": {
        "id": "M-GP8Ruhs9vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conllpp"
      ],
      "metadata": {
        "id": "CtA8L6egNEl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conllpp_cpy = conllpp.map(lambda batch: {\"ner_tags_str\": [conllpp[\"train\"].features[\"ner_tags\"].feature.int2str(i) for i in batch[\"ner_tags\"]]}, batched=True)"
      ],
      "metadata": {
        "id": "d-0GTzp0tx2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")"
      ],
      "metadata": {
        "id": "wKgDSqYOz99l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conllpp_cpy[\"train\"].to_pandas().head()"
      ],
      "metadata": {
        "id": "iGqq8anqdkcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_tokenizer(conllpp_cpy[\"train\"][\"tokens\"], is_split_into_words=True).word_ids(1)"
      ],
      "metadata": {
        "id": "o9RVSGHQRS2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def align_labels_with_tokens(batch):\n",
        "    tokenized_inputs = model_tokenizer(batch[\"tokens\"], is_split_into_words=True)\n",
        "\n",
        "    aligned_labels = []\n",
        "\n",
        "    for i, word_ids in enumerate(tokenized_inputs.word_ids(batch_index=i) for i in range(len(batch[\"tokens\"]))):\n",
        "        previous_word = None\n",
        "        labels = []\n",
        "\n",
        "        for word_id in word_ids:\n",
        "            if word_id is None:\n",
        "                labels.append(-100)\n",
        "            elif word_id != previous_word:\n",
        "                labels.append(batch[\"ner_tags\"][i][word_id])\n",
        "            else:\n",
        "                labels.append(batch[\"ner_tags\"][i][word_id])\n",
        "\n",
        "            previous_word = word_id\n",
        "\n",
        "        aligned_labels.append(labels)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = aligned_labels\n",
        "    return tokenized_inputs"
      ],
      "metadata": {
        "id": "TZa2Jlw4tY5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prep_conllpp_cpy = conllpp_cpy.map(align_labels_with_tokens, batched=True)"
      ],
      "metadata": {
        "id": "11DtT0WBR9Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filt_prep_conllpp_cpy = prep_conllpp_cpy.remove_columns(['id', 'tokens', 'pos_tags',\n",
        "                                                         'chunk_tags', 'ner_tags', 'ner_tags_str'])\n",
        "\n",
        "filt_prep_conllpp_cpy"
      ],
      "metadata": {
        "id": "L02gBxBTR9uV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=model_tokenizer)"
      ],
      "metadata": {
        "id": "jAzhpvA_gpPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install seqeval\n",
        "!pip -q install evaluate"
      ],
      "metadata": {
        "id": "cz1FU-ijox4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate, numpy as np"
      ],
      "metadata": {
        "id": "HAivLwG3pECV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = evaluate.load(\"seqeval\")"
      ],
      "metadata": {
        "id": "q7qzKK2RpAKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p):\n",
        "    predictions, labels = np.argmax(p.predictions, axis=1), p.label_ids\n",
        "    predictions = [[conllpp[\"train\"].features[\"ner_tags\"].feature.int2str(pred) for pred in pred_seq] for pred_seq in predictions]\n",
        "    labels = [[conllpp[\"train\"].features[\"ner_tags\"].feature.int2str(label) for label in label_seq] for label_seq in labels]\n",
        "\n",
        "    results = metrics.compute(predictions=predictions, references=labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "hDRKUNQ5kLnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "id2label = {idx:lbl for idx,lbl in enumerate(conllpp[\"train\"].features[\"ner_tags\"].feature.names)}\n",
        "label2id = {lbl:idx for idx,lbl in enumerate(conllpp[\"train\"].features[\"ner_tags\"].feature.names)}"
      ],
      "metadata": {
        "id": "9-7kRItisAki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\"distilbert-base-cased\",\n",
        "                                                        id2label=id2label,\n",
        "                                                        label2id=label2id)"
      ],
      "metadata": {
        "id": "bkqCPxo4t_yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\"ner_bert\",\n",
        "                                  evaluation_strategy=\"epoch\",\n",
        "                                  logging_strategy=\"epoch\",\n",
        "                                  learning_rate=2e-5,\n",
        "                                  num_train_epochs=20,\n",
        "                                  weight_decay=0.01,\n",
        "                                  per_device_train_batch_size=64,\n",
        "                                  per_device_eval_batch_size=64,)\n",
        "\n",
        "trainer = Trainer(model=model,\n",
        "                  args=training_args,\n",
        "                  train_dataset=filt_prep_conllpp_cpy[\"train\"],\n",
        "                  eval_dataset=filt_prep_conllpp_cpy[\"validation\"],\n",
        "                  data_collator=data_collator,\n",
        "                  tokenizer=model_tokenizer,\n",
        "                  compute_metrics=compute_metrics)"
      ],
      "metadata": {
        "id": "7OwkXlKAh6LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "qkO1wjEup_3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LrrfhaUBuOPh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}